{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "from IPython.display import JSON\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.datasets.generators import create_object_detection, xyxy_to_xywh, xywh_to_xyxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can choose between datasets ['CUB_200'] that you can download.\n",
    "# We use an artifical generated classification dataset by default that doesn't require downloading.\n",
    "\n",
    "dataset = 'artifical'\n",
    "# dataset = 'CUB_200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'artifical':\n",
    "    import tempfile\n",
    "    tmp_dir = tempfile.TemporaryDirectory()\n",
    "    path = Path(tmp_dir.name)\n",
    "    print(path)\n",
    "    \n",
    "    project_path = path\n",
    "    project_file = path/'annotations.json'\n",
    "    image_dir = 'images'\n",
    "    label_dir = None\n",
    "    im_width=300 \n",
    "    im_height=300\n",
    "    \n",
    "    from PIL import Image\n",
    "\n",
    "    create_object_detection(path=path, n_samples=50, n_objects=(1, 1), size=(500, 500))\n",
    "    annotations = pd.read_json(path/'annotations.json').T\n",
    "\n",
    "    # Convert artifical dataset annotations to old bbox ipyannotator format\n",
    "    # {'imagename.jpg': {'x':0, 'y': 0, 'width': 100, 'heigth': 100}}\n",
    "    anno = annotations.T.to_dict('records')[1]\n",
    "    annotation_on_explore = {os.path.join(path, image_dir, k): dict(zip(['x', 'y', 'width', 'height'], xyxy_to_xywh(v))) for k, v in anno.items()}\n",
    "\n",
    "    with open(path/'annotations.json', 'w') as f:  \n",
    "        json.dump(annotation_on_explore, f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real DS example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.datasets.download import get_cub_200_2011\n",
    "\n",
    "if dataset == 'CUB_200':\n",
    "    get_cub_200_2011('data')\n",
    "\n",
    "    project_path = 'data/CUB_200_2011'\n",
    "    project_file = 'data/CUB_200_2011/annotaitons_bbox.json'\n",
    "    image_dir='images'\n",
    "    label_dir = None\n",
    "    im_width=50 \n",
    "    im_height=50\n",
    "    \n",
    "    # Let's generate annotattion.json file with bboxes for BBoxAnnotator\n",
    "\n",
    "    # bboxes\n",
    "    annotations = pd.read_csv('data/CUB_200_2011/bounding_boxes.txt', delimiter=' ',\n",
    "                              names='image_id x y width height'.split()).set_index('image_id')\n",
    "\n",
    "    # images \n",
    "    ims = pd.read_csv('data/CUB_200_2011/images.txt', delimiter=' ',\n",
    "                names='image_id image_name'.split()).set_index('image_id')\n",
    "\n",
    "    # join by image_id\n",
    "    anno_ = ims.join(annotations)\n",
    "\n",
    "    # use full path instead image name\n",
    "    im_dir = 'data/CUB_200_2011/images/'\n",
    "    anno_['image_name'] = im_dir + anno_['image_name'].astype(str)\n",
    "\n",
    "    # combine bbox data columns as single dict to match BBoxAnnotator format\n",
    "    columns = ['x', 'y', 'width', 'height']\n",
    "    anno_['bbox'] = anno_[columns].to_dict(orient='records')\n",
    "    anno_ = anno_.drop(columns=columns)\n",
    "\n",
    "    # save json {\"image_name\" : {bbox}, ... }\n",
    "    annotation_on_explore = anno_.set_index('image_name')['bbox'].to_dict()\n",
    "\n",
    "    with open('data/CUB_200_2011/annotaitons_bbox.json', 'w') as f:  \n",
    "        json.dump(annotation_on_explore, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annotated dataset and visualize it to get a feel for it.\n",
    "\n",
    "- real\n",
    "- generated\n",
    "- labeled\n",
    "- unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.bbox_annotator import BBoxAnnotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize existing annotated dataset.\n",
    "\n",
    "We use `results_dir` param to indicate directory where `annotation.json` file with existing annotations is located.\n",
    "\n",
    "You can explore dataset with `next/previous` buttons to check visualized bboxs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = BBoxAnnotator(project_path=project_path, file_name=project_file, canvas_size=(300,200), image_dir=image_dir)\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check existing labels \n",
    "list(bb.to_dict().items())[10:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load unannotated dataset and create classification labels.\n",
    "\n",
    "- real\n",
    "- generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set `results_dir=\"out\"` to define that final `annotation.json` file will be saved to `{project_path}/out` direcory. No existing annotations are used now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = BBoxAnnotator(project_path=project_path, canvas_size=(300, 200), image_dir=image_dir, results_dir='out')\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(sig):\n",
    "    s = (sig[2] + sig[3]) // 2\n",
    "    return (sig + (np.random.rand(1, 4) * s - s/2)).astype(int).tolist()[0]\n",
    "\n",
    "augment(np.array([10,10,10,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.datasets.generators import sample_bbox\n",
    "\n",
    "\n",
    "filt = np.random.uniform(low=0, high=1, size=len(annotation_on_explore))\n",
    "\n",
    "bbox_noise = 0.1\n",
    "\n",
    "# lets randomly annotate each image from code and save annotations\n",
    "for k, f_ in tqdm(zip(bb._model.annotations.keys(), filt)):\n",
    "    if f_ < bbox_noise:\n",
    "        bb._model.annotations[k]=dict(zip(['x', 'y', 'width', 'height'], \n",
    "                                          augment(np.fromiter(annotation_on_explore[k].values(), dtype=np.uint64))))\n",
    "    else:\n",
    "        bb._model.annotations[k] = annotation_on_explore[k]\n",
    "        \n",
    "bb._model._update_coords() # update screen\n",
    "\n",
    "bb._save_btn.click() #save to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same in memory\n",
    "list(bb.to_dict().items())[10:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb._model.annotation_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annotated dataset and mark wrongly annotated samples.\n",
    "\n",
    "- real\n",
    "- generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open labels generated on [create] step\n",
    "\n",
    "with open(bb._model.annotation_file_path) as infile:\n",
    "    annotation_on_create = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to artificial bbox format ->\n",
    "# if dataset == 'artifical':\n",
    "di = {k: xywh_to_xyxy([v['x'], v['y'], v['width'], v['height']]) if v else [] for k, v in annotation_on_create.items()}\n",
    "list(di.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save drawn bboxes to real img files\n",
    "\n",
    "from ipyannotator.datasets.generators import draw_bbox\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "\n",
    "captured_path = Path(project_path) / \"captured\"\n",
    "\n",
    "for im, bbx in tqdm(di.items()):\n",
    "    # use captured_path instead image_dir, keeping the folder structure\n",
    "    old_im_path = Path(im)\n",
    "    index = old_im_path.parts.index(image_dir)+1\n",
    "    new_im_path = captured_path.joinpath(*old_im_path.parts[index:])\n",
    "    new_im_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    _image = Image.open(im)\n",
    "    if bbx:\n",
    "        try:           \n",
    "            # todo: debug draw_bbox: function takes exactly 1 argument (3 given)\n",
    "            _image = draw_bbox(bbx, im=_image, black=False, values=False, width=3+np.prod(_image.size)//50000)\n",
    "        except Exception as e: \n",
    "            pass \n",
    "    _image.save(new_im_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should __mark all errors__ (images, with bboxs that aren't closely around an object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.capture_annotator import CaptureAnnotator\n",
    "\n",
    "c = CaptureAnnotator(project_path, image_dir='captured', \n",
    "                     image_width=150, image_height=150, \n",
    "                     n_rows=2, n_cols=4,\n",
    "                     question=f'Check images with incorrect or empty bbox annotation', \n",
    "                     results_dir=f'missed')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark incorrect bboxes from code\n",
    "\n",
    "im_dir_path = Path(project_path) / image_dir\n",
    "\n",
    "for k, v in tqdm(c._model.annotations.items()):\n",
    "    capture_im_path = Path(k)\n",
    "    \n",
    "    index = capture_im_path.parts.index('captured') + 1\n",
    "    new_im_path = im_dir_path.joinpath(*capture_im_path.parts[index:])\n",
    "    \n",
    "    v_expl =annotation_on_explore.get(str(new_im_path), {})\n",
    "    v_cret =annotation_on_create.get(str(new_im_path), {})\n",
    "    \n",
    "    c._model.annotations[k] = {'answer': v_expl != v_cret}   \n",
    "    c._model._update_state()\n",
    "    \n",
    "c._save_btn.click()\n",
    "# print(c._model.annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get list of all images which incorrect bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get list of images with absent or incorrect annotations marked on previous above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k, v in c.to_dict().items() if v['answer']][:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
